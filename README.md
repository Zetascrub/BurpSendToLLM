# ğŸ§  Send to LLM Enhanced (Burp Extension)

Send to LLM Enhanced is a Burp Suite extension that integrates powerful AI analysis into your web security workflow. It allows you to send HTTP requests directly from Burp to a locally or remotely hosted large language model (LLM) for intelligent insights and automated assessments.
## âœ¨ Features

    ğŸ” Right-click "Send to â†’" Menu
    Use context menus to send requests to specialized AI tools:

        Analyze Request â€“ General-purpose LLM analysis

        Header Analyzer â€“ Review HTTP headers for missing security features

        Param Guess Helper â€“ Suggest hidden or common fuzzing parameters

        Vuln Suggestor â€“ Automatically identify potential vulnerabilities (e.g., CSP, CORS, XSS)

        Payload Generator â€“ Create attack payloads like XSS or SQLi

    ğŸ“‹ History Tab
    Track all prompts and LLM responses in a scrollable, resizable panel.

    ğŸ›  Pentester Tools Tab
    Test different prompt templates interactively within the extension.

    ğŸ’¬ Custom Templates
    Modify or add your own prompt formats via the "Config" tab.

## ğŸ“¸ Screenshots

### ğŸ”¹ Context Menu - "Send to â†’"
![SendTo Menu](Images/SendTo.png)

### ğŸ”¹ Vuln Suggestor Output (in History Tab)
![Vuln Suggestor Output](Images/VulnSuggestor.png)


## âš™ï¸ Requirements

```
Burp Suite Professional or Community

Java 8+

A local or remote LLM endpoint (e.g. Ollama or OpenAI-compatible server)
```

## ğŸš€ Usage

    Load the .jar file into Burp via the Extender â†’ Extensions tab.

    Right-click any request in the Proxy or Repeater tab.

    Choose Extensions â†’ Send to LLM Enhanced â†’ Send to â†’ [Tool].

    View the result in the LLM Console under the History tab or try other tools in the Pentester Tools tab.

## ğŸ§  Model Compatibility

This extension is designed to work with any OpenAI-compatible API endpoint. By default, it targets:

POST http://localhost:11434/v1/chat/completions
Model: llama3.2

This is compatible with Ollama, but can be customized in the Config tab.
### ğŸ“ Customization (WIP)

    Add your own prompt templates via the Config tab.

    Adjust model and endpoint fields as needed for different environments.

## ğŸ“¦ Building

```bash
javac -cp burpsuite_pro_v2025.2.4.jar:json-20230227.jar BurpExtender.java
jar cf SendToLLM.jar BurpExtender.class
```

or

```bash
./build.sh burpsuite_pro_v2025.2.4.jar json-20230227.jar
```